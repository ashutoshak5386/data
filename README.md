# ğŸ­ 2D Avatar Gautam

This project extracts and processes **visemes** (mouth shapes for lip-sync) from a video, applies post-processing, and generates reusable video clips for **2D avatars**.

---

## ğŸ“‚ Project Structure

2D-AVATAR-GAUTAM/
â”‚â”€â”€ viseme_1/ # Example output folder for viseme images
â”‚â”€â”€ visemes/ # Auto-generated folder for viseme crops
â”‚â”€â”€ .gitignore
â”‚â”€â”€ annotation.py # Main script: extracts visemes from video
â”‚â”€â”€ postprocessing.py # Fades edges of viseme images
â”‚â”€â”€ repeat_video.py # Loops idle video for smooth playback
â”‚â”€â”€ Avatar IV Video.mp4 # Input video (face with speech)
â”‚â”€â”€ Avatar IV Video.wav # Input audio for lip-sync cues
â”‚â”€â”€ coords.json # Saved mouth coordinates + angles
â”‚â”€â”€ data.json # Example lip-sync timing data
â”‚â”€â”€ idle.mp4 # Idle animation clip
â”‚â”€â”€ idle_repeated.mp4 # Auto-generated repeated idle loop
â”‚â”€â”€ output_with_landmarks.mp4 # Debug video with facial landmarks drawn
â”‚â”€â”€ requirements.txt # Dependencies


---

## âš™ï¸ Dependencies

Install Python libraries (**Python 3.8â€“3.11 recommended**):


pip install -r requirements.txt
Contents of requirements.txt:


opencv-python
mediapipe
numpy
moviepy
ğŸš€ How It Works
1. Viseme Extraction (annotation.py)
Loads a video and lip-sync data (mouthCues with start/end times).

Uses MediaPipe FaceMesh to detect face + mouth landmarks.

Crops the mouth region for each unique viseme and saves as PNG.

Saves bounding boxes, angles, and timestamps in coords.json.

Creates a debug video output_with_landmarks.mp4 showing:

Face mesh landmarks

Mouth bounding box

Current viseme label

Run:


python annotation.py
2. Post-Processing (postprocessing.py)
Applies a fade effect on edges of viseme images for smoother blending.

Saves processed images with _processed.png suffix.




python postprocessing.py
3. Idle Video Looping (repeat_video.py)
Doubles the length of idle.mp4 by concatenating it with itself.

Output is idle_repeated.mp4.


python repeat_video.py
ğŸ“Š Outputs
Viseme Images â†’ Cropped mouth PNGs stored in /visemes

Landmarked Video â†’ output_with_landmarks.mp4

Mouth Coordinates â†’ coords.json (bounding boxes, angles)

Processed PNGs â†’ _processed.png files with transparency

Idle Loops â†’ idle_repeated.mp4

ğŸ—ï¸ System Architecture

                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Input Video (MP4)  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  annotation.py       â”‚
                   â”‚  (MouthCropper)      â”‚
                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                   â”‚ Uses MediaPipe Face â”‚
                   â”‚ Mesh for landmarks  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                   â”‚                   â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Viseme Images â”‚   â”‚ coords.json  â”‚   â”‚ output_with_   â”‚
 â”‚   (cropped)    â”‚   â”‚  (angles,    â”‚   â”‚ landmarks.mp4  â”‚
 â”‚                â”‚   â”‚  bounding box)â”‚   â”‚ (debug video) â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Viseme Images â”€â”€â–º postprocessing.py â”€â”€â–º Processed PNGs (alpha faded)

idle.mp4 â”€â”€â–º repeat_video.py â”€â”€â–º idle_repeated.mp4
ğŸ”„ Flow Diagram (Data Pipeline)


[Start]
   â”‚
   â–¼
Load Input Video + Lip Sync Data (mouthCues)
   â”‚
   â–¼
Run MediaPipe FaceMesh â†’ Detect face + mouth landmarks
   â”‚
   â–¼
Extract mouth bounding box
   â”‚
   â”œâ”€â”€â–º Crop mouth region â†’ Save as Viseme.png
   â”‚
   â”œâ”€â”€â–º Calculate mouth angle + bbox coords â†’ Save in coords.json
   â”‚
   â””â”€â”€â–º Draw landmarks + label on frame â†’ Save debug video
   â”‚
   â–¼
[End of annotation.py]
   â”‚
   â”œâ”€â”€â–º (Optional) postprocessing.py â†’ fade viseme PNG edges
   â”‚
   â””â”€â”€â–º (Optional) repeat_video.py â†’ extend idle animation
ğŸ”® Possible Extensions
Support multiple viseme sets (different speakers)

Replace cropped visemes directly in avatar templates

Improve idle blending with crossfade instead of hard repeat

Integrate with real-time speech-to-viseme mapping
